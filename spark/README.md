# Spark
Shortcomings of Map/Reduce:
   - Have to force your pipeline into map/reduce steps
   - Relies heavily on reading data from disk
   - Only native JAVA programming interface

Spark - same features of map/reduce but more
   - 20 highly efficient distributed operations
   - In-memory caching of data
   - Native Python, Scala interface; interactive shells
   
We will do some join exercises in spark:
  - [Simple Join](https://github.com/juliaawu/coursera-hadoop-platform-and-application-framework/tree/master/spark/simple-join-assignment)
  - [Advanced Join](https://github.com/juliaawu/coursera-hadoop-platform-and-application-framework/tree/master/spark/advanced-join-assignment)